{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers, models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D\n",
    "model.add(layers.Conv2D(32,(3,3), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "\n",
    "    첫 번째 인자: 컨볼루션 필터의 수\n",
    "\n",
    "    두 번째 인자, 컨볼루션 커널의 (행,열)\n",
    "\n",
    "    padding: 경계 처리 방법을 정의\n",
    "\n",
    "        'valid'(padding 이미지 위쪽):유효한 영역만 출력, 따라서 출력 이미지 사이즈는 입력 사이즈보다 적음\n",
    "\n",
    "                4x4 -> 3x3 -> 2x2 \n",
    "\n",
    "        'same'(padding 이미지 아래쪽):출력 이미지 사이즈가 입력 이미지 사이즈와 동일\n",
    "               \n",
    "               가장자리에 가로,세로로 1줄씩 추가 한 후 Conv2D를 돌려서 사이즈가 줄어들지 않게 함\n",
    "\n",
    "               예) 3x3이 있었다고 한다면, 가장자리에 1줄씩 추가해서 4x4로 시작, 결과값은 3x3이 되지만, 한쪽 방향으로 쏠리게 되어있음\n",
    "    \n",
    "    input_shape: 샘플 수를 제외한 입력 형태를 정의. 모델에서 첫 레이어일 때만 정의하면 됨\n",
    "\n",
    "        (행, 열, 채널 수)로 정의, 흑백영상인 경우에는 채널이 1이고, 컬러 영상인 경우에는 채널이 3으로 설정\n",
    "\n",
    "    activation: 활성화 함수 설정\n",
    "\n",
    "        'linear': 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력\n",
    "\n",
    "        'relu': rectifier 함수, 은닉층에 주로 쓰임\n",
    "\n",
    "        'sigmoid': 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰임\n",
    "\n",
    "        'softmax': 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰임    \n",
    "    \n",
    "    Con2D => 이미지를 나눠서(예를들면 이미지를 8등분해서) 그 특징들을 배움\n",
    "\n",
    "    이미지를 배우려면 3차원 데이터가 필요함( 가로+세로, 컬러 혹은 흑백, 강조)\n",
    "\n",
    "    예를들면 흑백은 [28,28,1], 컬러는 [28,28,[rgb값]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling 레이어\n",
    "\n",
    "max_pooling 이미지 참고!\n",
    "\n",
    "    그림에서 외각선일 경우(이미지의 그라데이션 차이가 많이 날 경우) 수치가 높아지는데\n",
    "\n",
    "    그럴 경우 다른 바탕색은 제거하고 중요한 외각선 데이터만 뽑아내는것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten()\n",
    "\n",
    "Conv2D나 Maxpooling으로 나온 결과값 (2D~3D) 데이터를 1D 타입으로 길게 만들어 주는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 다운 및 변형\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000,28,28,1)) # 60000개를 28x28 그리고 흑백이니까 1로 바꿔달라\n",
    "train_images = train_images.astype('float32') # 실수형으로 데이터 변형\n",
    "\n",
    "# 테스트 데이터도 변경\n",
    "test_images = test_images.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# 라벨 데이터 변경\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3093 - accuracy: 0.9337\n",
      "Epoch 2/7\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0644 - accuracy: 0.9819\n",
      "Epoch 3/7\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0503 - accuracy: 0.9866\n",
      "Epoch 4/7\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0452 - accuracy: 0.9886\n",
      "Epoch 5/7\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0428 - accuracy: 0.9891\n",
      "Epoch 6/7\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0416 - accuracy: 0.9899\n",
      "Epoch 7/7\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0404 - accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161d46315a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=7, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1112 - accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "# 데이터 테스트\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolutional Neural Network)\n",
    "\n",
    "    CNN은 이미지를 인식하기위해 패턴을 찾는데 특히 유용함\n",
    "\n",
    "    데이터에서 직접 학습하고 패턴을 사용해 이미지를 분류(특징을 수동으로 추출 할 필요X)\n",
    "\n",
    "    이러한 장점때문에 자율주행자동차, 얼굴인식과 같은 객체인식이나 computer vision이 필요한 분야에 많이 사용되는 중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN을 사용하기 위해서는\n",
    "\n",
    "    Conovolution(합성곱) 사용!\n",
    "\n",
    "        사진을 쪼개서 확대한 후 가르침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e89c93e4c07d4ac8f065cea982a638287e1c61026788fcbbad7e0263e2130583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
